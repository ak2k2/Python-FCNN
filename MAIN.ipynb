{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_if_possible(val):\n",
    "    try:\n",
    "        float_val = float(val)\n",
    "        if float_val.is_integer():\n",
    "            return int(float_val)\n",
    "        else:\n",
    "            return float_val\n",
    "    except ValueError:\n",
    "        return val\n",
    "\n",
    "\n",
    "# MODES are \"grades\" or \"bc\"\n",
    "MODE = \"grades\"\n",
    "\n",
    "test_file = f\"{MODE}_test.csv\"\n",
    "train_file = f\"{MODE}_train.csv\"\n",
    "\n",
    "# use a converter to make sure that all integers in the file (wihtout .) are stored as integers in to pandas dataframe\n",
    "test_df = pd.read_csv(\n",
    "    test_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")\n",
    "train_df = pd.read_csv(\n",
    "    train_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=364.435\n",
      ">epoch=1, lrate=0.100, error=329.420\n",
      ">epoch=2, lrate=0.100, error=326.723\n",
      ">epoch=3, lrate=0.100, error=325.118\n",
      ">epoch=4, lrate=0.100, error=324.031\n",
      ">epoch=5, lrate=0.100, error=323.303\n",
      ">epoch=6, lrate=0.100, error=322.799\n",
      ">epoch=7, lrate=0.100, error=322.419\n",
      ">epoch=8, lrate=0.100, error=322.095\n",
      ">epoch=9, lrate=0.100, error=321.775\n",
      ">epoch=10, lrate=0.100, error=321.414\n",
      ">epoch=11, lrate=0.100, error=320.962\n",
      ">epoch=12, lrate=0.100, error=320.344\n",
      ">epoch=13, lrate=0.100, error=319.430\n",
      ">epoch=14, lrate=0.100, error=317.940\n",
      ">epoch=15, lrate=0.100, error=315.199\n",
      ">epoch=16, lrate=0.100, error=309.436\n",
      ">epoch=17, lrate=0.100, error=295.126\n",
      ">epoch=18, lrate=0.100, error=266.603\n",
      ">epoch=19, lrate=0.100, error=235.158\n",
      ">epoch=20, lrate=0.100, error=209.583\n",
      ">epoch=21, lrate=0.100, error=190.593\n",
      ">epoch=22, lrate=0.100, error=176.628\n",
      ">epoch=23, lrate=0.100, error=166.130\n",
      ">epoch=24, lrate=0.100, error=158.008\n",
      ">epoch=25, lrate=0.100, error=151.556\n",
      ">epoch=26, lrate=0.100, error=146.316\n",
      ">epoch=27, lrate=0.100, error=141.975\n",
      ">epoch=28, lrate=0.100, error=138.316\n",
      ">epoch=29, lrate=0.100, error=135.183\n",
      ">epoch=30, lrate=0.100, error=132.463\n",
      ">epoch=31, lrate=0.100, error=130.073\n",
      ">epoch=32, lrate=0.100, error=127.950\n",
      ">epoch=33, lrate=0.100, error=126.045\n",
      ">epoch=34, lrate=0.100, error=124.322\n",
      ">epoch=35, lrate=0.100, error=122.752\n",
      ">epoch=36, lrate=0.100, error=121.312\n",
      ">epoch=37, lrate=0.100, error=119.985\n",
      ">epoch=38, lrate=0.100, error=118.755\n",
      ">epoch=39, lrate=0.100, error=117.611\n",
      ">epoch=40, lrate=0.100, error=116.542\n",
      ">epoch=41, lrate=0.100, error=115.540\n",
      ">epoch=42, lrate=0.100, error=114.599\n",
      ">epoch=43, lrate=0.100, error=113.711\n",
      ">epoch=44, lrate=0.100, error=112.873\n",
      ">epoch=45, lrate=0.100, error=112.079\n",
      ">epoch=46, lrate=0.100, error=111.325\n",
      ">epoch=47, lrate=0.100, error=110.609\n",
      ">epoch=48, lrate=0.100, error=109.928\n",
      ">epoch=49, lrate=0.100, error=109.278\n",
      ">epoch=50, lrate=0.100, error=108.657\n",
      ">epoch=51, lrate=0.100, error=108.063\n",
      ">epoch=52, lrate=0.100, error=107.494\n",
      ">epoch=53, lrate=0.100, error=106.949\n",
      ">epoch=54, lrate=0.100, error=106.426\n",
      ">epoch=55, lrate=0.100, error=105.924\n",
      ">epoch=56, lrate=0.100, error=105.441\n",
      ">epoch=57, lrate=0.100, error=104.975\n",
      ">epoch=58, lrate=0.100, error=104.527\n",
      ">epoch=59, lrate=0.100, error=104.095\n",
      ">epoch=60, lrate=0.100, error=103.678\n",
      ">epoch=61, lrate=0.100, error=103.275\n",
      ">epoch=62, lrate=0.100, error=102.886\n",
      ">epoch=63, lrate=0.100, error=102.509\n",
      ">epoch=64, lrate=0.100, error=102.145\n",
      ">epoch=65, lrate=0.100, error=101.792\n",
      ">epoch=66, lrate=0.100, error=101.450\n",
      ">epoch=67, lrate=0.100, error=101.118\n",
      ">epoch=68, lrate=0.100, error=100.796\n",
      ">epoch=69, lrate=0.100, error=100.484\n",
      ">epoch=70, lrate=0.100, error=100.181\n",
      ">epoch=71, lrate=0.100, error=99.886\n",
      ">epoch=72, lrate=0.100, error=99.599\n",
      ">epoch=73, lrate=0.100, error=99.321\n",
      ">epoch=74, lrate=0.100, error=99.049\n",
      ">epoch=75, lrate=0.100, error=98.785\n",
      ">epoch=76, lrate=0.100, error=98.528\n",
      ">epoch=77, lrate=0.100, error=98.277\n",
      ">epoch=78, lrate=0.100, error=98.033\n",
      ">epoch=79, lrate=0.100, error=97.795\n",
      ">epoch=80, lrate=0.100, error=97.562\n",
      ">epoch=81, lrate=0.100, error=97.335\n",
      ">epoch=82, lrate=0.100, error=97.114\n",
      ">epoch=83, lrate=0.100, error=96.898\n",
      ">epoch=84, lrate=0.100, error=96.687\n",
      ">epoch=85, lrate=0.100, error=96.480\n",
      ">epoch=86, lrate=0.100, error=96.278\n",
      ">epoch=87, lrate=0.100, error=96.081\n",
      ">epoch=88, lrate=0.100, error=95.888\n",
      ">epoch=89, lrate=0.100, error=95.699\n",
      ">epoch=90, lrate=0.100, error=95.515\n",
      ">epoch=91, lrate=0.100, error=95.334\n",
      ">epoch=92, lrate=0.100, error=95.157\n",
      ">epoch=93, lrate=0.100, error=94.983\n",
      ">epoch=94, lrate=0.100, error=94.813\n",
      ">epoch=95, lrate=0.100, error=94.647\n",
      ">epoch=96, lrate=0.100, error=94.484\n",
      ">epoch=97, lrate=0.100, error=94.324\n",
      ">epoch=98, lrate=0.100, error=94.167\n",
      ">epoch=99, lrate=0.100, error=94.013\n",
      ">epoch=100, lrate=0.100, error=93.862\n",
      ">epoch=101, lrate=0.100, error=93.714\n",
      ">epoch=102, lrate=0.100, error=93.569\n",
      ">epoch=103, lrate=0.100, error=93.426\n",
      ">epoch=104, lrate=0.100, error=93.286\n",
      ">epoch=105, lrate=0.100, error=93.148\n",
      ">epoch=106, lrate=0.100, error=93.013\n",
      ">epoch=107, lrate=0.100, error=92.880\n",
      ">epoch=108, lrate=0.100, error=92.750\n",
      ">epoch=109, lrate=0.100, error=92.622\n",
      ">epoch=110, lrate=0.100, error=92.496\n",
      ">epoch=111, lrate=0.100, error=92.372\n",
      ">epoch=112, lrate=0.100, error=92.251\n",
      ">epoch=113, lrate=0.100, error=92.131\n",
      ">epoch=114, lrate=0.100, error=92.013\n",
      ">epoch=115, lrate=0.100, error=91.897\n",
      ">epoch=116, lrate=0.100, error=91.784\n",
      ">epoch=117, lrate=0.100, error=91.672\n",
      ">epoch=118, lrate=0.100, error=91.561\n",
      ">epoch=119, lrate=0.100, error=91.453\n",
      ">epoch=120, lrate=0.100, error=91.346\n",
      ">epoch=121, lrate=0.100, error=91.241\n",
      ">epoch=122, lrate=0.100, error=91.138\n",
      ">epoch=123, lrate=0.100, error=91.036\n",
      ">epoch=124, lrate=0.100, error=90.935\n",
      ">epoch=125, lrate=0.100, error=90.837\n",
      ">epoch=126, lrate=0.100, error=90.739\n",
      ">epoch=127, lrate=0.100, error=90.644\n",
      ">epoch=128, lrate=0.100, error=90.549\n",
      ">epoch=129, lrate=0.100, error=90.456\n",
      ">epoch=130, lrate=0.100, error=90.365\n",
      ">epoch=131, lrate=0.100, error=90.275\n",
      ">epoch=132, lrate=0.100, error=90.186\n",
      ">epoch=133, lrate=0.100, error=90.098\n",
      ">epoch=134, lrate=0.100, error=90.012\n",
      ">epoch=135, lrate=0.100, error=89.927\n",
      ">epoch=136, lrate=0.100, error=89.843\n",
      ">epoch=137, lrate=0.100, error=89.760\n",
      ">epoch=138, lrate=0.100, error=89.678\n",
      ">epoch=139, lrate=0.100, error=89.598\n",
      ">epoch=140, lrate=0.100, error=89.519\n",
      ">epoch=141, lrate=0.100, error=89.441\n",
      ">epoch=142, lrate=0.100, error=89.364\n",
      ">epoch=143, lrate=0.100, error=89.288\n",
      ">epoch=144, lrate=0.100, error=89.213\n",
      ">epoch=145, lrate=0.100, error=89.139\n",
      ">epoch=146, lrate=0.100, error=89.067\n",
      ">epoch=147, lrate=0.100, error=88.995\n",
      ">epoch=148, lrate=0.100, error=88.924\n",
      ">epoch=149, lrate=0.100, error=88.854\n",
      ">epoch=150, lrate=0.100, error=88.786\n",
      ">epoch=151, lrate=0.100, error=88.718\n",
      ">epoch=152, lrate=0.100, error=88.651\n",
      ">epoch=153, lrate=0.100, error=88.585\n",
      ">epoch=154, lrate=0.100, error=88.520\n",
      ">epoch=155, lrate=0.100, error=88.456\n",
      ">epoch=156, lrate=0.100, error=88.393\n",
      ">epoch=157, lrate=0.100, error=88.331\n",
      ">epoch=158, lrate=0.100, error=88.269\n",
      ">epoch=159, lrate=0.100, error=88.209\n",
      ">epoch=160, lrate=0.100, error=88.149\n",
      ">epoch=161, lrate=0.100, error=88.090\n",
      ">epoch=162, lrate=0.100, error=88.033\n",
      ">epoch=163, lrate=0.100, error=87.976\n",
      ">epoch=164, lrate=0.100, error=87.919\n",
      ">epoch=165, lrate=0.100, error=87.864\n",
      ">epoch=166, lrate=0.100, error=87.810\n",
      ">epoch=167, lrate=0.100, error=87.756\n",
      ">epoch=168, lrate=0.100, error=87.704\n",
      ">epoch=169, lrate=0.100, error=87.652\n",
      ">epoch=170, lrate=0.100, error=87.601\n",
      ">epoch=171, lrate=0.100, error=87.550\n",
      ">epoch=172, lrate=0.100, error=87.501\n",
      ">epoch=173, lrate=0.100, error=87.453\n",
      ">epoch=174, lrate=0.100, error=87.405\n",
      ">epoch=175, lrate=0.100, error=87.358\n",
      ">epoch=176, lrate=0.100, error=87.312\n",
      ">epoch=177, lrate=0.100, error=87.267\n",
      ">epoch=178, lrate=0.100, error=87.223\n",
      ">epoch=179, lrate=0.100, error=87.180\n",
      ">epoch=180, lrate=0.100, error=87.137\n",
      ">epoch=181, lrate=0.100, error=87.096\n",
      ">epoch=182, lrate=0.100, error=87.055\n",
      ">epoch=183, lrate=0.100, error=87.015\n",
      ">epoch=184, lrate=0.100, error=86.976\n",
      ">epoch=185, lrate=0.100, error=86.938\n",
      ">epoch=186, lrate=0.100, error=86.901\n",
      ">epoch=187, lrate=0.100, error=86.865\n",
      ">epoch=188, lrate=0.100, error=86.829\n",
      ">epoch=189, lrate=0.100, error=86.795\n",
      ">epoch=190, lrate=0.100, error=86.761\n",
      ">epoch=191, lrate=0.100, error=86.729\n",
      ">epoch=192, lrate=0.100, error=86.697\n",
      ">epoch=193, lrate=0.100, error=86.666\n",
      ">epoch=194, lrate=0.100, error=86.636\n",
      ">epoch=195, lrate=0.100, error=86.607\n",
      ">epoch=196, lrate=0.100, error=86.579\n",
      ">epoch=197, lrate=0.100, error=86.551\n",
      ">epoch=198, lrate=0.100, error=86.524\n",
      ">epoch=199, lrate=0.100, error=86.499\n",
      ">epoch=200, lrate=0.100, error=86.473\n",
      ">epoch=201, lrate=0.100, error=86.449\n",
      ">epoch=202, lrate=0.100, error=86.426\n",
      ">epoch=203, lrate=0.100, error=86.404\n",
      ">epoch=204, lrate=0.100, error=86.383\n",
      ">epoch=205, lrate=0.100, error=86.364\n",
      ">epoch=206, lrate=0.100, error=86.347\n",
      ">epoch=207, lrate=0.100, error=86.334\n",
      ">epoch=208, lrate=0.100, error=86.325\n",
      ">epoch=209, lrate=0.100, error=86.323\n",
      ">epoch=210, lrate=0.100, error=86.328\n",
      ">epoch=211, lrate=0.100, error=86.344\n",
      ">epoch=212, lrate=0.100, error=86.372\n",
      ">epoch=213, lrate=0.100, error=86.414\n",
      ">epoch=214, lrate=0.100, error=86.469\n",
      ">epoch=215, lrate=0.100, error=86.536\n",
      ">epoch=216, lrate=0.100, error=86.614\n",
      ">epoch=217, lrate=0.100, error=86.699\n",
      ">epoch=218, lrate=0.100, error=86.788\n",
      ">epoch=219, lrate=0.100, error=86.876\n",
      ">epoch=220, lrate=0.100, error=86.961\n",
      ">epoch=221, lrate=0.100, error=87.040\n",
      ">epoch=222, lrate=0.100, error=87.110\n",
      ">epoch=223, lrate=0.100, error=87.172\n",
      ">epoch=224, lrate=0.100, error=87.223\n",
      ">epoch=225, lrate=0.100, error=87.263\n",
      ">epoch=226, lrate=0.100, error=87.294\n",
      ">epoch=227, lrate=0.100, error=87.313\n",
      ">epoch=228, lrate=0.100, error=87.322\n",
      ">epoch=229, lrate=0.100, error=87.322\n",
      ">epoch=230, lrate=0.100, error=87.311\n",
      ">epoch=231, lrate=0.100, error=87.290\n",
      ">epoch=232, lrate=0.100, error=87.259\n",
      ">epoch=233, lrate=0.100, error=87.218\n",
      ">epoch=234, lrate=0.100, error=87.168\n",
      ">epoch=235, lrate=0.100, error=87.108\n",
      ">epoch=236, lrate=0.100, error=87.039\n",
      ">epoch=237, lrate=0.100, error=86.962\n",
      ">epoch=238, lrate=0.100, error=86.875\n",
      ">epoch=239, lrate=0.100, error=86.780\n",
      ">epoch=240, lrate=0.100, error=86.676\n",
      ">epoch=241, lrate=0.100, error=86.565\n",
      ">epoch=242, lrate=0.100, error=86.447\n",
      ">epoch=243, lrate=0.100, error=86.321\n",
      ">epoch=244, lrate=0.100, error=86.190\n",
      ">epoch=245, lrate=0.100, error=86.052\n",
      ">epoch=246, lrate=0.100, error=85.908\n",
      ">epoch=247, lrate=0.100, error=85.760\n",
      ">epoch=248, lrate=0.100, error=85.607\n",
      ">epoch=249, lrate=0.100, error=85.450\n",
      ">epoch=250, lrate=0.100, error=85.289\n",
      ">epoch=251, lrate=0.100, error=85.125\n",
      ">epoch=252, lrate=0.100, error=84.958\n",
      ">epoch=253, lrate=0.100, error=84.788\n",
      ">epoch=254, lrate=0.100, error=84.617\n",
      ">epoch=255, lrate=0.100, error=84.443\n",
      ">epoch=256, lrate=0.100, error=84.269\n",
      ">epoch=257, lrate=0.100, error=84.093\n",
      ">epoch=258, lrate=0.100, error=83.916\n",
      ">epoch=259, lrate=0.100, error=83.738\n",
      ">epoch=260, lrate=0.100, error=83.560\n",
      ">epoch=261, lrate=0.100, error=83.382\n",
      ">epoch=262, lrate=0.100, error=83.204\n",
      ">epoch=263, lrate=0.100, error=83.027\n",
      ">epoch=264, lrate=0.100, error=82.849\n",
      ">epoch=265, lrate=0.100, error=82.672\n",
      ">epoch=266, lrate=0.100, error=82.496\n",
      ">epoch=267, lrate=0.100, error=82.321\n",
      ">epoch=268, lrate=0.100, error=82.146\n",
      ">epoch=269, lrate=0.100, error=81.973\n",
      ">epoch=270, lrate=0.100, error=81.801\n",
      ">epoch=271, lrate=0.100, error=81.629\n",
      ">epoch=272, lrate=0.100, error=81.459\n",
      ">epoch=273, lrate=0.100, error=81.291\n",
      ">epoch=274, lrate=0.100, error=81.123\n",
      ">epoch=275, lrate=0.100, error=80.957\n",
      ">epoch=276, lrate=0.100, error=80.793\n",
      ">epoch=277, lrate=0.100, error=80.630\n",
      ">epoch=278, lrate=0.100, error=80.468\n",
      ">epoch=279, lrate=0.100, error=80.308\n",
      ">epoch=280, lrate=0.100, error=80.149\n",
      ">epoch=281, lrate=0.100, error=79.992\n",
      ">epoch=282, lrate=0.100, error=79.836\n",
      ">epoch=283, lrate=0.100, error=79.682\n",
      ">epoch=284, lrate=0.100, error=79.530\n",
      ">epoch=285, lrate=0.100, error=79.379\n",
      ">epoch=286, lrate=0.100, error=79.229\n",
      ">epoch=287, lrate=0.100, error=79.081\n",
      ">epoch=288, lrate=0.100, error=78.935\n",
      ">epoch=289, lrate=0.100, error=78.790\n",
      ">epoch=290, lrate=0.100, error=78.646\n",
      ">epoch=291, lrate=0.100, error=78.504\n",
      ">epoch=292, lrate=0.100, error=78.363\n",
      ">epoch=293, lrate=0.100, error=78.224\n",
      ">epoch=294, lrate=0.100, error=78.087\n",
      ">epoch=295, lrate=0.100, error=77.951\n",
      ">epoch=296, lrate=0.100, error=77.816\n",
      ">epoch=297, lrate=0.100, error=77.682\n",
      ">epoch=298, lrate=0.100, error=77.550\n",
      ">epoch=299, lrate=0.100, error=77.420\n",
      ">epoch=300, lrate=0.100, error=77.291\n",
      ">epoch=301, lrate=0.100, error=77.163\n",
      ">epoch=302, lrate=0.100, error=77.036\n",
      ">epoch=303, lrate=0.100, error=76.911\n",
      ">epoch=304, lrate=0.100, error=76.787\n",
      ">epoch=305, lrate=0.100, error=76.664\n",
      ">epoch=306, lrate=0.100, error=76.543\n",
      ">epoch=307, lrate=0.100, error=76.422\n",
      ">epoch=308, lrate=0.100, error=76.303\n",
      ">epoch=309, lrate=0.100, error=76.186\n",
      ">epoch=310, lrate=0.100, error=76.069\n",
      ">epoch=311, lrate=0.100, error=75.954\n",
      ">epoch=312, lrate=0.100, error=75.839\n",
      ">epoch=313, lrate=0.100, error=75.726\n",
      ">epoch=314, lrate=0.100, error=75.614\n",
      ">epoch=315, lrate=0.100, error=75.503\n",
      ">epoch=316, lrate=0.100, error=75.394\n",
      ">epoch=317, lrate=0.100, error=75.285\n",
      ">epoch=318, lrate=0.100, error=75.177\n",
      ">epoch=319, lrate=0.100, error=75.071\n",
      ">epoch=320, lrate=0.100, error=74.965\n",
      ">epoch=321, lrate=0.100, error=74.860\n",
      ">epoch=322, lrate=0.100, error=74.757\n",
      ">epoch=323, lrate=0.100, error=74.654\n",
      ">epoch=324, lrate=0.100, error=74.553\n",
      ">epoch=325, lrate=0.100, error=74.452\n",
      ">epoch=326, lrate=0.100, error=74.352\n",
      ">epoch=327, lrate=0.100, error=74.253\n",
      ">epoch=328, lrate=0.100, error=74.156\n",
      ">epoch=329, lrate=0.100, error=74.059\n",
      ">epoch=330, lrate=0.100, error=73.963\n",
      ">epoch=331, lrate=0.100, error=73.867\n",
      ">epoch=332, lrate=0.100, error=73.773\n",
      ">epoch=333, lrate=0.100, error=73.680\n",
      ">epoch=334, lrate=0.100, error=73.587\n",
      ">epoch=335, lrate=0.100, error=73.495\n",
      ">epoch=336, lrate=0.100, error=73.404\n",
      ">epoch=337, lrate=0.100, error=73.314\n",
      ">epoch=338, lrate=0.100, error=73.225\n",
      ">epoch=339, lrate=0.100, error=73.136\n",
      ">epoch=340, lrate=0.100, error=73.048\n",
      ">epoch=341, lrate=0.100, error=72.961\n",
      ">epoch=342, lrate=0.100, error=72.875\n",
      ">epoch=343, lrate=0.100, error=72.790\n",
      ">epoch=344, lrate=0.100, error=72.705\n",
      ">epoch=345, lrate=0.100, error=72.621\n",
      ">epoch=346, lrate=0.100, error=72.537\n",
      ">epoch=347, lrate=0.100, error=72.455\n",
      ">epoch=348, lrate=0.100, error=72.373\n",
      ">epoch=349, lrate=0.100, error=72.291\n",
      ">epoch=350, lrate=0.100, error=72.211\n",
      ">epoch=351, lrate=0.100, error=72.131\n",
      ">epoch=352, lrate=0.100, error=72.052\n",
      ">epoch=353, lrate=0.100, error=71.973\n",
      ">epoch=354, lrate=0.100, error=71.895\n",
      ">epoch=355, lrate=0.100, error=71.818\n",
      ">epoch=356, lrate=0.100, error=71.741\n",
      ">epoch=357, lrate=0.100, error=71.665\n",
      ">epoch=358, lrate=0.100, error=71.589\n",
      ">epoch=359, lrate=0.100, error=71.515\n",
      ">epoch=360, lrate=0.100, error=71.440\n",
      ">epoch=361, lrate=0.100, error=71.367\n",
      ">epoch=362, lrate=0.100, error=71.294\n",
      ">epoch=363, lrate=0.100, error=71.221\n",
      ">epoch=364, lrate=0.100, error=71.149\n",
      ">epoch=365, lrate=0.100, error=71.078\n",
      ">epoch=366, lrate=0.100, error=71.007\n",
      ">epoch=367, lrate=0.100, error=70.936\n",
      ">epoch=368, lrate=0.100, error=70.867\n",
      ">epoch=369, lrate=0.100, error=70.797\n",
      ">epoch=370, lrate=0.100, error=70.729\n",
      ">epoch=371, lrate=0.100, error=70.660\n",
      ">epoch=372, lrate=0.100, error=70.593\n",
      ">epoch=373, lrate=0.100, error=70.526\n",
      ">epoch=374, lrate=0.100, error=70.459\n",
      ">epoch=375, lrate=0.100, error=70.393\n",
      ">epoch=376, lrate=0.100, error=70.327\n",
      ">epoch=377, lrate=0.100, error=70.262\n",
      ">epoch=378, lrate=0.100, error=70.197\n",
      ">epoch=379, lrate=0.100, error=70.133\n",
      ">epoch=380, lrate=0.100, error=70.069\n",
      ">epoch=381, lrate=0.100, error=70.006\n",
      ">epoch=382, lrate=0.100, error=69.943\n",
      ">epoch=383, lrate=0.100, error=69.880\n",
      ">epoch=384, lrate=0.100, error=69.818\n",
      ">epoch=385, lrate=0.100, error=69.757\n",
      ">epoch=386, lrate=0.100, error=69.696\n",
      ">epoch=387, lrate=0.100, error=69.635\n",
      ">epoch=388, lrate=0.100, error=69.575\n",
      ">epoch=389, lrate=0.100, error=69.515\n",
      ">epoch=390, lrate=0.100, error=69.455\n",
      ">epoch=391, lrate=0.100, error=69.396\n",
      ">epoch=392, lrate=0.100, error=69.338\n",
      ">epoch=393, lrate=0.100, error=69.280\n",
      ">epoch=394, lrate=0.100, error=69.222\n",
      ">epoch=395, lrate=0.100, error=69.164\n",
      ">epoch=396, lrate=0.100, error=69.107\n",
      ">epoch=397, lrate=0.100, error=69.051\n",
      ">epoch=398, lrate=0.100, error=68.994\n",
      ">epoch=399, lrate=0.100, error=68.938\n",
      ">epoch=400, lrate=0.100, error=68.883\n",
      ">epoch=401, lrate=0.100, error=68.828\n",
      ">epoch=402, lrate=0.100, error=68.773\n",
      ">epoch=403, lrate=0.100, error=68.719\n",
      ">epoch=404, lrate=0.100, error=68.664\n",
      ">epoch=405, lrate=0.100, error=68.611\n",
      ">epoch=406, lrate=0.100, error=68.557\n",
      ">epoch=407, lrate=0.100, error=68.504\n",
      ">epoch=408, lrate=0.100, error=68.452\n",
      ">epoch=409, lrate=0.100, error=68.399\n",
      ">epoch=410, lrate=0.100, error=68.347\n",
      ">epoch=411, lrate=0.100, error=68.296\n",
      ">epoch=412, lrate=0.100, error=68.244\n",
      ">epoch=413, lrate=0.100, error=68.193\n",
      ">epoch=414, lrate=0.100, error=68.143\n",
      ">epoch=415, lrate=0.100, error=68.092\n",
      ">epoch=416, lrate=0.100, error=68.042\n",
      ">epoch=417, lrate=0.100, error=67.992\n",
      ">epoch=418, lrate=0.100, error=67.943\n",
      ">epoch=419, lrate=0.100, error=67.894\n",
      ">epoch=420, lrate=0.100, error=67.845\n",
      ">epoch=421, lrate=0.100, error=67.796\n",
      ">epoch=422, lrate=0.100, error=67.748\n",
      ">epoch=423, lrate=0.100, error=67.700\n",
      ">epoch=424, lrate=0.100, error=67.653\n",
      ">epoch=425, lrate=0.100, error=67.605\n",
      ">epoch=426, lrate=0.100, error=67.558\n",
      ">epoch=427, lrate=0.100, error=67.511\n",
      ">epoch=428, lrate=0.100, error=67.465\n",
      ">epoch=429, lrate=0.100, error=67.418\n",
      ">epoch=430, lrate=0.100, error=67.372\n",
      ">epoch=431, lrate=0.100, error=67.327\n",
      ">epoch=432, lrate=0.100, error=67.281\n",
      ">epoch=433, lrate=0.100, error=67.236\n",
      ">epoch=434, lrate=0.100, error=67.191\n",
      ">epoch=435, lrate=0.100, error=67.147\n",
      ">epoch=436, lrate=0.100, error=67.102\n",
      ">epoch=437, lrate=0.100, error=67.058\n",
      ">epoch=438, lrate=0.100, error=67.014\n",
      ">epoch=439, lrate=0.100, error=66.971\n",
      ">epoch=440, lrate=0.100, error=66.927\n",
      ">epoch=441, lrate=0.100, error=66.884\n",
      ">epoch=442, lrate=0.100, error=66.841\n",
      ">epoch=443, lrate=0.100, error=66.799\n",
      ">epoch=444, lrate=0.100, error=66.756\n",
      ">epoch=445, lrate=0.100, error=66.714\n",
      ">epoch=446, lrate=0.100, error=66.672\n",
      ">epoch=447, lrate=0.100, error=66.630\n",
      ">epoch=448, lrate=0.100, error=66.589\n",
      ">epoch=449, lrate=0.100, error=66.548\n",
      ">epoch=450, lrate=0.100, error=66.507\n",
      ">epoch=451, lrate=0.100, error=66.466\n",
      ">epoch=452, lrate=0.100, error=66.425\n",
      ">epoch=453, lrate=0.100, error=66.385\n",
      ">epoch=454, lrate=0.100, error=66.345\n",
      ">epoch=455, lrate=0.100, error=66.305\n",
      ">epoch=456, lrate=0.100, error=66.265\n",
      ">epoch=457, lrate=0.100, error=66.226\n",
      ">epoch=458, lrate=0.100, error=66.187\n",
      ">epoch=459, lrate=0.100, error=66.148\n",
      ">epoch=460, lrate=0.100, error=66.109\n",
      ">epoch=461, lrate=0.100, error=66.070\n",
      ">epoch=462, lrate=0.100, error=66.032\n",
      ">epoch=463, lrate=0.100, error=65.993\n",
      ">epoch=464, lrate=0.100, error=65.955\n",
      ">epoch=465, lrate=0.100, error=65.918\n",
      ">epoch=466, lrate=0.100, error=65.880\n",
      ">epoch=467, lrate=0.100, error=65.843\n",
      ">epoch=468, lrate=0.100, error=65.805\n",
      ">epoch=469, lrate=0.100, error=65.768\n",
      ">epoch=470, lrate=0.100, error=65.731\n",
      ">epoch=471, lrate=0.100, error=65.695\n",
      ">epoch=472, lrate=0.100, error=65.658\n",
      ">epoch=473, lrate=0.100, error=65.622\n",
      ">epoch=474, lrate=0.100, error=65.586\n",
      ">epoch=475, lrate=0.100, error=65.550\n",
      ">epoch=476, lrate=0.100, error=65.514\n",
      ">epoch=477, lrate=0.100, error=65.479\n",
      ">epoch=478, lrate=0.100, error=65.443\n",
      ">epoch=479, lrate=0.100, error=65.408\n",
      ">epoch=480, lrate=0.100, error=65.373\n",
      ">epoch=481, lrate=0.100, error=65.338\n",
      ">epoch=482, lrate=0.100, error=65.304\n",
      ">epoch=483, lrate=0.100, error=65.269\n",
      ">epoch=484, lrate=0.100, error=65.235\n",
      ">epoch=485, lrate=0.100, error=65.201\n",
      ">epoch=486, lrate=0.100, error=65.167\n",
      ">epoch=487, lrate=0.100, error=65.133\n",
      ">epoch=488, lrate=0.100, error=65.099\n",
      ">epoch=489, lrate=0.100, error=65.066\n",
      ">epoch=490, lrate=0.100, error=65.032\n",
      ">epoch=491, lrate=0.100, error=64.999\n",
      ">epoch=492, lrate=0.100, error=64.966\n",
      ">epoch=493, lrate=0.100, error=64.933\n",
      ">epoch=494, lrate=0.100, error=64.901\n",
      ">epoch=495, lrate=0.100, error=64.868\n",
      ">epoch=496, lrate=0.100, error=64.836\n",
      ">epoch=497, lrate=0.100, error=64.804\n",
      ">epoch=498, lrate=0.100, error=64.771\n",
      ">epoch=499, lrate=0.100, error=64.740\n",
      "All of the hyperparameters of this NN are: {'hidden_layer': [{'weights': [-0.10163746441602615, -0.1284504635271783, -0.12810194661756366, -0.10256997918337948, -0.12358505366206912, 4.410349526822337, 1.3293075571395898, 6.211470723445864, -4.858284412631231], 'output': 0.6157111206822061, 'delta': -0.007038688289677431}], 'output_layer': [{'weights': [14.530125320066428, -1.9211214930556264], 'output': 0.9991116341471423, 'delta': 7.884927956216967e-07}, {'weights': [16.310789934287946, -7.602610955062883], 'output': 0.9197759989219834, 'delta': 0.0059195774746722}, {'weights': [13.686519378451578, -10.722043360963033], 'output': 0.09161696616726851, 'delta': -0.007624666047654821}, {'weights': [6.425150756346747, -6.702808726101468], 'output': 0.060295907408870086, 'delta': -0.0034163848633181992}]}\n"
     ]
    }
   ],
   "source": [
    "from FCNN import (\n",
    "    initialize_network,\n",
    "    predict,\n",
    "    predict_multiclass,\n",
    "    train_network,\n",
    "    read_configuration_file,\n",
    "    accuracy_score,\n",
    "    F1_score,\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in train_df.itertuples(index=False, name=None)\n",
    "]\n",
    "test_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in test_df.itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 500\n",
    "n_inputs = len(train_dataset[0]) - 1\n",
    "n_outputs = 1 if MODE == \"bc\" else 4\n",
    "network = initialize_network(n_inputs, 1, n_outputs)\n",
    "trained_network = train_network(network, train_dataset, 0.1, NUM_EPOCHS, n_outputs)\n",
    "\n",
    "print(f\"All of the hyperparameters of this NN are: {trained_network}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 81.93979933110369\n",
      "\n",
      "Accuracy on test data: 86.86868686868688\n"
     ]
    }
   ],
   "source": [
    "# TESTING ON UNSEEN DATA\n",
    "\n",
    "test_predictions = list()\n",
    "train_predictions = list()\n",
    "\n",
    "\n",
    "if MODE == \"bc\":\n",
    "    for row in test_dataset:\n",
    "        prediction = predict(trained_network, row)\n",
    "        test_predictions.append(prediction)\n",
    "\n",
    "    for row in train_dataset:\n",
    "        prediction = predict(trained_network, row)\n",
    "        train_predictions.append(prediction)\n",
    "\n",
    "    accuracy_on_test_data = accuracy_score(\n",
    "        [[row[-1]] for row in test_dataset], test_predictions\n",
    "    )\n",
    "    accuracy_on_train_data = accuracy_score(\n",
    "        [[row[-1]] for row in train_dataset], train_predictions\n",
    "    )\n",
    "    f1_test = F1_score([row[-1] for row in test_dataset], test_predictions)\n",
    "    f1_train = F1_score([row[-1] for row in train_dataset], train_predictions)\n",
    "    print(f\"Accuracy on training data: {accuracy_on_train_data}\")\n",
    "    print(f\"F1 score on training data: {f1_train}\")\n",
    "    print()\n",
    "    print(f\"Accuracy on test data: {accuracy_on_test_data}\")\n",
    "    print(f\"F1 score on test data: {f1_test}\")\n",
    "else:\n",
    "    for row in test_dataset:\n",
    "        prediction = predict(trained_network, row)\n",
    "        test_predictions.append(prediction)\n",
    "\n",
    "    for row in train_dataset:\n",
    "        prediction = predict(trained_network, row)\n",
    "        train_predictions.append(prediction)\n",
    "\n",
    "    # we now have the last four cols of test to compare to the predictions. we can define accuracy as follows:\n",
    "    # (1)\tOverall accuracy = (A + D) / (A + B + C + D); this is the fraction of examples that are correctly predicted with respect to the current class. Overall accuracy is generally considered a poor evaluation metric for Boolean classification tasks. If most examples do not belong to most classes, a system can achieve a high overall accuracy by trivially predicting that all examples belong to no classes.\n",
    "\n",
    "    accuracy_on_test_data = accuracy_score(\n",
    "        [row[-n_outputs:] for row in test_dataset], test_predictions\n",
    "    )\n",
    "    accuracy_on_train_data = accuracy_score(\n",
    "        [row[-n_outputs:] for row in train_dataset], train_predictions\n",
    "    )\n",
    "\n",
    "    print(f\"Accuracy on training data: {accuracy_on_train_data}\")\n",
    "    print()\n",
    "    print(f\"Accuracy on test data: {accuracy_on_test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Actual     Predicted\n",
       "0  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "1  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "2  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "3  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "4  [1, 1, 0, 0]  [1, 1, 0, 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Actual\": [\n",
    "            row[-n_outputs + 1 :][0] if n_outputs == 2 else row[-n_outputs:]\n",
    "            for row in train_dataset\n",
    "        ],\n",
    "        \"Predicted\": train_predictions,\n",
    "    }\n",
    ")\n",
    "\n",
    "table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false predictions: 54\n"
     ]
    }
   ],
   "source": [
    "false_predictions = table_df[table_df[\"Actual\"] != table_df[\"Predicted\"]]\n",
    "print(f\"Number of false predictions: {len(false_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if MODE == \"bc\":\n",
    "    cm = confusion_matrix(\n",
    "        [[row[-1]] for row in test_dataset], test_predictions, normalize=\"true\"\n",
    "    )\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        xticklabels=[\"0\", \"1\"],\n",
    "        yticklabels=[\"0\", \"1\"],\n",
    "        cmap=\"Blues\",\n",
    "        cbar=False,\n",
    "    )\n",
    "    ax.set_title\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Actual     Predicted\n",
       "0  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "1  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "2  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "3  [1, 1, 1, 0]  [1, 1, 1, 0]\n",
       "4  [1, 1, 0, 0]  [1, 1, 0, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a table where [row[-4:] for row in train_dataset] is the lleft side, and the right side is train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
