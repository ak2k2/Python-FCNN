{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_if_possible(val):\n",
    "    try:\n",
    "        float_val = float(val)\n",
    "        if float_val.is_integer():\n",
    "            return int(float_val)\n",
    "        else:\n",
    "            return float_val\n",
    "    except ValueError:\n",
    "        return val\n",
    "\n",
    "\n",
    "MODE = \"breast_cancer\"\n",
    "\n",
    "test_file = \"bc_test.csv\"\n",
    "train_file = \"bc_train.csv\"\n",
    "\n",
    "# use a converter to make sure that all integers in the file (wihtout .) are stored as integers in to pandas dataframe\n",
    "test_df = pd.read_csv(\n",
    "    test_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")\n",
    "train_df = pd.read_csv(\n",
    "    train_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=194.408\n",
      ">epoch=1, lrate=0.100, error=196.044\n",
      ">epoch=2, lrate=0.100, error=194.910\n",
      ">epoch=3, lrate=0.100, error=190.286\n",
      ">epoch=4, lrate=0.100, error=182.767\n",
      ">epoch=5, lrate=0.100, error=172.916\n",
      ">epoch=6, lrate=0.100, error=160.860\n",
      ">epoch=7, lrate=0.100, error=147.502\n",
      ">epoch=8, lrate=0.100, error=134.286\n",
      ">epoch=9, lrate=0.100, error=122.324\n",
      ">epoch=10, lrate=0.100, error=112.073\n",
      ">epoch=11, lrate=0.100, error=103.515\n",
      ">epoch=12, lrate=0.100, error=96.422\n",
      ">epoch=13, lrate=0.100, error=90.521\n",
      ">epoch=14, lrate=0.100, error=85.566\n",
      ">epoch=15, lrate=0.100, error=81.357\n",
      ">epoch=16, lrate=0.100, error=77.737\n",
      ">epoch=17, lrate=0.100, error=74.586\n",
      ">epoch=18, lrate=0.100, error=71.815\n",
      ">epoch=19, lrate=0.100, error=69.353\n",
      ">epoch=20, lrate=0.100, error=67.151\n",
      ">epoch=21, lrate=0.100, error=65.165\n",
      ">epoch=22, lrate=0.100, error=63.365\n",
      ">epoch=23, lrate=0.100, error=61.724\n",
      ">epoch=24, lrate=0.100, error=60.221\n",
      ">epoch=25, lrate=0.100, error=58.836\n",
      ">epoch=26, lrate=0.100, error=57.556\n",
      ">epoch=27, lrate=0.100, error=56.367\n",
      ">epoch=28, lrate=0.100, error=55.257\n",
      ">epoch=29, lrate=0.100, error=54.219\n",
      ">epoch=30, lrate=0.100, error=53.243\n",
      ">epoch=31, lrate=0.100, error=52.323\n",
      ">epoch=32, lrate=0.100, error=51.453\n",
      ">epoch=33, lrate=0.100, error=50.627\n",
      ">epoch=34, lrate=0.100, error=49.843\n",
      ">epoch=35, lrate=0.100, error=49.096\n",
      ">epoch=36, lrate=0.100, error=48.382\n",
      ">epoch=37, lrate=0.100, error=47.698\n",
      ">epoch=38, lrate=0.100, error=47.043\n",
      ">epoch=39, lrate=0.100, error=46.414\n",
      ">epoch=40, lrate=0.100, error=45.808\n",
      ">epoch=41, lrate=0.100, error=45.225\n",
      ">epoch=42, lrate=0.100, error=44.663\n",
      ">epoch=43, lrate=0.100, error=44.121\n",
      ">epoch=44, lrate=0.100, error=43.596\n",
      ">epoch=45, lrate=0.100, error=43.089\n",
      ">epoch=46, lrate=0.100, error=42.598\n",
      ">epoch=47, lrate=0.100, error=42.122\n",
      ">epoch=48, lrate=0.100, error=41.661\n",
      ">epoch=49, lrate=0.100, error=41.213\n",
      ">epoch=50, lrate=0.100, error=40.779\n",
      ">epoch=51, lrate=0.100, error=40.357\n",
      ">epoch=52, lrate=0.100, error=39.947\n",
      ">epoch=53, lrate=0.100, error=39.548\n",
      ">epoch=54, lrate=0.100, error=39.159\n",
      ">epoch=55, lrate=0.100, error=38.781\n",
      ">epoch=56, lrate=0.100, error=38.412\n",
      ">epoch=57, lrate=0.100, error=38.053\n",
      ">epoch=58, lrate=0.100, error=37.702\n",
      ">epoch=59, lrate=0.100, error=37.360\n",
      ">epoch=60, lrate=0.100, error=37.025\n",
      ">epoch=61, lrate=0.100, error=36.699\n",
      ">epoch=62, lrate=0.100, error=36.379\n",
      ">epoch=63, lrate=0.100, error=36.067\n",
      ">epoch=64, lrate=0.100, error=35.762\n",
      ">epoch=65, lrate=0.100, error=35.463\n",
      ">epoch=66, lrate=0.100, error=35.171\n",
      ">epoch=67, lrate=0.100, error=34.886\n",
      ">epoch=68, lrate=0.100, error=34.607\n",
      ">epoch=69, lrate=0.100, error=34.334\n",
      ">epoch=70, lrate=0.100, error=34.068\n",
      ">epoch=71, lrate=0.100, error=33.808\n",
      ">epoch=72, lrate=0.100, error=33.553\n",
      ">epoch=73, lrate=0.100, error=33.305\n",
      ">epoch=74, lrate=0.100, error=33.063\n",
      ">epoch=75, lrate=0.100, error=32.827\n",
      ">epoch=76, lrate=0.100, error=32.597\n",
      ">epoch=77, lrate=0.100, error=32.372\n",
      ">epoch=78, lrate=0.100, error=32.154\n",
      ">epoch=79, lrate=0.100, error=31.940\n",
      ">epoch=80, lrate=0.100, error=31.732\n",
      ">epoch=81, lrate=0.100, error=31.529\n",
      ">epoch=82, lrate=0.100, error=31.331\n",
      ">epoch=83, lrate=0.100, error=31.138\n",
      ">epoch=84, lrate=0.100, error=30.950\n",
      ">epoch=85, lrate=0.100, error=30.766\n",
      ">epoch=86, lrate=0.100, error=30.586\n",
      ">epoch=87, lrate=0.100, error=30.410\n",
      ">epoch=88, lrate=0.100, error=30.238\n",
      ">epoch=89, lrate=0.100, error=30.070\n",
      ">epoch=90, lrate=0.100, error=29.906\n",
      ">epoch=91, lrate=0.100, error=29.745\n",
      ">epoch=92, lrate=0.100, error=29.587\n",
      ">epoch=93, lrate=0.100, error=29.432\n",
      ">epoch=94, lrate=0.100, error=29.281\n",
      ">epoch=95, lrate=0.100, error=29.132\n",
      ">epoch=96, lrate=0.100, error=28.986\n",
      ">epoch=97, lrate=0.100, error=28.843\n",
      ">epoch=98, lrate=0.100, error=28.703\n",
      ">epoch=99, lrate=0.100, error=28.565\n",
      "All of the hyperparameters of this NN are: {'hidden_layer': [{'weights': [0.24929642377239217, -1.958178887105776, -0.7885153747898822, -1.491493121456695, 0.9291220587421756, 0.8626002660769213, -1.0791476239513755, -3.82890754262246, 2.346082030786486, 3.272284238175281, -1.8300208900285175, 0.5908195412961186, -0.3545497492171174, -2.2570412596475617, -0.9396897784032414, 0.7321926273588519, 0.21826075087196484, 1.6594109354596178, -0.3798199313401181, 1.5039210868357127, -2.4612265316659454, -2.5962324295999686, -1.3796577391930251, -2.8485666318342164, -2.56312870795595, -0.5186317870040265, -1.4027378390236767, -1.6485124531931965, -1.4039613294173137, 0.039418027638842036, 5.832458652153926], 'output': 0.9610409898540575, 'delta': 0.00010190957161001872}], 'output_layer': [{'weights': [-8.179763584879417, 3.532491318832762], 'output': 0.01301484185601713, 'delta': -0.00016718157512191846}, {'weights': [8.191268809395305, -3.5379046544536896], 'output': 0.9870574591191729, 'delta': 0.0001653413676545418}]}\n"
     ]
    }
   ],
   "source": [
    "from FCNN import (\n",
    "    initialize_network,\n",
    "    predict,\n",
    "    train_network,\n",
    "    read_configuration_file,\n",
    "    accuracy_score,\n",
    "    F1_score,\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in train_df.itertuples(index=False, name=None)\n",
    "]\n",
    "test_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in test_df.itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "n_inputs = len(train_dataset[0]) - 1\n",
    "n_outputs = 2 if MODE == \"breast_cancer\" else 4\n",
    "network = initialize_network(n_inputs, 1, n_outputs)\n",
    "trained_network = train_network(network, train_dataset, 0.1, NUM_EPOCHS, n_outputs)\n",
    "\n",
    "print(f\"All of the hyperparameters of this NN are: {trained_network}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 97.32441471571906\n",
      "F1 score on training data: 0.9732441471571907\n",
      "\n",
      "Accuracy on test data: 97.01492537313433\n",
      "F1 score on test data: 0.9701492537313433\n"
     ]
    }
   ],
   "source": [
    "# TESTING ON UNSEEN DATA\n",
    "\n",
    "test_predictions = list()\n",
    "train_predictions = list()\n",
    "\n",
    "for row in test_dataset:\n",
    "    prediction = predict(trained_network, row)\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "for row in train_dataset:\n",
    "    prediction = predict(trained_network, row)\n",
    "    train_predictions.append(prediction)\n",
    "\n",
    "accuracy_on_test_data = accuracy_score(\n",
    "    [row[-1] for row in test_dataset], test_predictions\n",
    ")\n",
    "accuracy_on_train_data = accuracy_score(\n",
    "    [row[-1] for row in train_dataset], train_predictions\n",
    ")\n",
    "\n",
    "f1_test = F1_score([row[-1] for row in test_dataset], test_predictions)\n",
    "f1_train = F1_score([row[-1] for row in train_dataset], train_predictions)\n",
    "\n",
    "print(f\"Accuracy on training data: {accuracy_on_train_data}\")\n",
    "print(f\"F1 score on training data: {f1_train}\")\n",
    "print()\n",
    "print(f\"Accuracy on test data: {accuracy_on_test_data}\")\n",
    "print(f\"F1 score on test data: {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "\n",
    "\n",
    "def do_clustering(test_df, train_df):\n",
    "    df = test_df  # set the dataframe to the test dataframe\n",
    "    column_names = [f\"feature_{i}\" for i in len(df.columns)]\n",
    "    column_names[-1] = \"Y\"  # set the last column to be the Y col (target)\n",
    "    # add column names to dataframe\n",
    "    test_df.columns = column_names\n",
    "    train_df.columns = column_names\n",
    "    pairs = 5\n",
    "    # clusters = KMeans(n_clusters=2, init=\"k-means++\", max_iter=1000, random_state=0).fit(X)\n",
    "    # clusters = DBSCAN(eps=0.5, min_samples=5).fit(X) # this does -1 or 0\n",
    "    X = df.drop(\"Y\", axis=1)\n",
    "    clusters = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "    Y = df[\"Y\"]\n",
    "    print(clusters.labels_)\n",
    "    accuracy = accuracy_score(Y, clusters.labels_)\n",
    "\n",
    "    # All unique pairs of the first #'pairs' columns\n",
    "    pairs_of_columns = list(itertools.combinations(column_names[:pairs], 2))\n",
    "\n",
    "    n_pairs = len(pairs_of_columns)\n",
    "    grid_size = int(n_pairs**0.5) + 1  # Square root of number of pairs, rounded up\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    # Plot each pair in its respective subplot\n",
    "    for ax, (a, b) in zip(axes.flatten(), pairs_of_columns):\n",
    "        ax.scatter(df[a], df[b], c=clusters.labels_, s=3)\n",
    "        ax.set_xlabel(a)\n",
    "        ax.set_ylabel(b)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for i in range(n_pairs, grid_size**2):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "\n",
    "    # make a header nice loooking box for the title and some text\n",
    "    title = f\"KMeans (n=2) Clustering of Breast Cancer Data Feature Combinations. \\n\\nBINARY CLASSIFICATION ACCURACY: {str(accuracy * 100)+ '%'}\"\n",
    "\n",
    "    # Add a title and a subtitle\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "do_clustering(\n",
    "    test_df, train_df\n",
    ")  # preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\n",
    "\n",
    "do_clustering(\n",
    "    test_df, train_df\n",
    ")  # preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
