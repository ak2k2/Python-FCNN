{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def convert_if_possible(val):\n",
    "    try:\n",
    "        float_val = float(val)\n",
    "        if float_val.is_integer():\n",
    "            return int(float_val)\n",
    "        else:\n",
    "            return float_val\n",
    "    except ValueError:\n",
    "        return val\n",
    "\n",
    "\n",
    "MODE = \"breast_cancer\"\n",
    "\n",
    "test_file = \"bc_test.csv\"\n",
    "train_file = \"bc_train.csv\"\n",
    "\n",
    "# use a converter to make sure that all integers in the file (wihtout .) are stored as integers in to pandas dataframe\n",
    "test_df = pd.read_csv(\n",
    "    test_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")\n",
    "train_df = pd.read_csv(\n",
    "    train_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/armaan/Desktop/Fall-2023 Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# Show the plot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m do_clustering(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     test_df, train_df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m )  \u001b[39m# preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m do_clustering(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     test_df, train_df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )  \u001b[39m# preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\u001b[39;00m\n",
      "\u001b[1;32m/Users/armaan/Desktop/Fall-2023 Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_clustering\u001b[39m(test_df, train_df):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df \u001b[39m=\u001b[39m test_df  \u001b[39m# set the dataframe to the test dataframe\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     column_names \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfeature_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     column_names[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# set the last column to be the Y col (target)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# add column names to dataframe\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "def do_clustering(test_df, train_df):\n",
    "    df = test_df  # set the dataframe to the test dataframe\n",
    "    column_names = [f\"feature_{i}\" for i in len(df.columns)]\n",
    "    column_names[-1] = \"Y\"  # set the last column to be the Y col (target)\n",
    "    # add column names to dataframe\n",
    "    test_df.columns = column_names\n",
    "    train_df.columns = column_names\n",
    "    pairs = 5\n",
    "    # clusters = KMeans(n_clusters=2, init=\"k-means++\", max_iter=1000, random_state=0).fit(X)\n",
    "    # clusters = DBSCAN(eps=0.5, min_samples=5).fit(X) # this does -1 or 0\n",
    "    X = df.drop(\"Y\", axis=1)\n",
    "    clusters = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "    Y = df[\"Y\"]\n",
    "    print(clusters.labels_)\n",
    "    accuracy = accuracy_score(Y, clusters.labels_)\n",
    "\n",
    "    # All unique pairs of the first #'pairs' columns\n",
    "    pairs_of_columns = list(itertools.combinations(column_names[:pairs], 2))\n",
    "\n",
    "    n_pairs = len(pairs_of_columns)\n",
    "    grid_size = int(n_pairs**0.5) + 1  # Square root of number of pairs, rounded up\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    # Plot each pair in its respective subplot\n",
    "    for ax, (a, b) in zip(axes.flatten(), pairs_of_columns):\n",
    "        ax.scatter(df[a], df[b], c=clusters.labels_, s=3)\n",
    "        ax.set_xlabel(a)\n",
    "        ax.set_ylabel(b)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for i in range(n_pairs, grid_size**2):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "\n",
    "    # make a header nice loooking box for the title and some text\n",
    "    title = f\"KMeans (n=2) Clustering of Breast Cancer Data Feature Combinations. \\n\\nBINARY CLASSIFICATION ACCURACY: {str(accuracy * 100)+ '%'}\"\n",
    "\n",
    "    # Add a title and a subtitle\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "do_clustering(\n",
    "    test_df, train_df\n",
    ")  # preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\n",
    "\n",
    "do_clustering(\n",
    "    test_df, train_df\n",
    ")  # preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.200, error=181.228\n",
      ">epoch=1, lrate=0.200, error=194.310\n",
      ">epoch=2, lrate=0.200, error=191.347\n",
      ">epoch=3, lrate=0.200, error=185.617\n",
      ">epoch=4, lrate=0.200, error=172.737\n",
      ">epoch=5, lrate=0.200, error=150.744\n",
      ">epoch=6, lrate=0.200, error=126.791\n",
      ">epoch=7, lrate=0.200, error=107.073\n",
      ">epoch=8, lrate=0.200, error=92.816\n",
      ">epoch=9, lrate=0.200, error=82.697\n",
      ">epoch=10, lrate=0.200, error=75.275\n",
      ">epoch=11, lrate=0.200, error=69.612\n",
      ">epoch=12, lrate=0.200, error=65.165\n",
      ">epoch=13, lrate=0.200, error=61.601\n",
      ">epoch=14, lrate=0.200, error=58.685\n",
      ">epoch=15, lrate=0.200, error=56.247\n",
      ">epoch=16, lrate=0.200, error=54.170\n",
      ">epoch=17, lrate=0.200, error=52.370\n",
      ">epoch=18, lrate=0.200, error=50.787\n",
      ">epoch=19, lrate=0.200, error=49.377\n",
      ">epoch=20, lrate=0.200, error=48.106\n",
      ">epoch=21, lrate=0.200, error=46.950\n",
      ">epoch=22, lrate=0.200, error=45.888\n",
      ">epoch=23, lrate=0.200, error=44.905\n",
      ">epoch=24, lrate=0.200, error=43.991\n",
      ">epoch=25, lrate=0.200, error=43.136\n",
      ">epoch=26, lrate=0.200, error=42.334\n",
      ">epoch=27, lrate=0.200, error=41.579\n",
      ">epoch=28, lrate=0.200, error=40.868\n",
      ">epoch=29, lrate=0.200, error=40.196\n",
      ">epoch=30, lrate=0.200, error=39.561\n",
      ">epoch=31, lrate=0.200, error=38.959\n",
      ">epoch=32, lrate=0.200, error=38.388\n",
      ">epoch=33, lrate=0.200, error=37.843\n",
      ">epoch=34, lrate=0.200, error=37.324\n",
      ">epoch=35, lrate=0.200, error=36.827\n",
      ">epoch=36, lrate=0.200, error=36.349\n",
      ">epoch=37, lrate=0.200, error=35.889\n",
      ">epoch=38, lrate=0.200, error=35.443\n",
      ">epoch=39, lrate=0.200, error=35.012\n",
      ">epoch=40, lrate=0.200, error=34.593\n",
      ">epoch=41, lrate=0.200, error=34.185\n",
      ">epoch=42, lrate=0.200, error=33.787\n",
      ">epoch=43, lrate=0.200, error=33.400\n",
      ">epoch=44, lrate=0.200, error=33.021\n",
      ">epoch=45, lrate=0.200, error=32.651\n",
      ">epoch=46, lrate=0.200, error=32.291\n",
      ">epoch=47, lrate=0.200, error=31.939\n",
      ">epoch=48, lrate=0.200, error=31.595\n",
      ">epoch=49, lrate=0.200, error=31.260\n",
      ">epoch=50, lrate=0.200, error=30.935\n",
      ">epoch=51, lrate=0.200, error=30.619\n",
      ">epoch=52, lrate=0.200, error=30.313\n",
      ">epoch=53, lrate=0.200, error=30.020\n",
      ">epoch=54, lrate=0.200, error=29.738\n",
      ">epoch=55, lrate=0.200, error=29.468\n",
      ">epoch=56, lrate=0.200, error=29.209\n",
      ">epoch=57, lrate=0.200, error=28.961\n",
      ">epoch=58, lrate=0.200, error=28.723\n",
      ">epoch=59, lrate=0.200, error=28.493\n",
      ">epoch=60, lrate=0.200, error=28.272\n",
      ">epoch=61, lrate=0.200, error=28.057\n",
      ">epoch=62, lrate=0.200, error=27.849\n",
      ">epoch=63, lrate=0.200, error=27.647\n",
      ">epoch=64, lrate=0.200, error=27.450\n",
      ">epoch=65, lrate=0.200, error=27.258\n",
      ">epoch=66, lrate=0.200, error=27.070\n",
      ">epoch=67, lrate=0.200, error=26.887\n",
      ">epoch=68, lrate=0.200, error=26.708\n",
      ">epoch=69, lrate=0.200, error=26.532\n",
      ">epoch=70, lrate=0.200, error=26.359\n",
      ">epoch=71, lrate=0.200, error=26.190\n",
      ">epoch=72, lrate=0.200, error=26.024\n",
      ">epoch=73, lrate=0.200, error=25.861\n",
      ">epoch=74, lrate=0.200, error=25.701\n",
      ">epoch=75, lrate=0.200, error=25.543\n",
      ">epoch=76, lrate=0.200, error=25.388\n",
      ">epoch=77, lrate=0.200, error=25.235\n",
      ">epoch=78, lrate=0.200, error=25.085\n",
      ">epoch=79, lrate=0.200, error=24.937\n",
      ">epoch=80, lrate=0.200, error=24.791\n",
      ">epoch=81, lrate=0.200, error=24.648\n",
      ">epoch=82, lrate=0.200, error=24.506\n",
      ">epoch=83, lrate=0.200, error=24.367\n",
      ">epoch=84, lrate=0.200, error=24.229\n",
      ">epoch=85, lrate=0.200, error=24.094\n",
      ">epoch=86, lrate=0.200, error=23.961\n",
      ">epoch=87, lrate=0.200, error=23.829\n",
      ">epoch=88, lrate=0.200, error=23.699\n",
      ">epoch=89, lrate=0.200, error=23.572\n",
      ">epoch=90, lrate=0.200, error=23.446\n",
      ">epoch=91, lrate=0.200, error=23.321\n",
      ">epoch=92, lrate=0.200, error=23.199\n",
      ">epoch=93, lrate=0.200, error=23.078\n",
      ">epoch=94, lrate=0.200, error=22.960\n",
      ">epoch=95, lrate=0.200, error=22.842\n",
      ">epoch=96, lrate=0.200, error=22.727\n",
      ">epoch=97, lrate=0.200, error=22.613\n",
      ">epoch=98, lrate=0.200, error=22.501\n",
      ">epoch=99, lrate=0.200, error=22.391\n",
      "All of the hyperparameters of this NN are: {'hidden_layer': [{'weights': [-0.044794210482529954, -1.8983399814028188, -0.3411254872343245, -2.1593048968853634, 0.1818173983712941, 1.296420626474983, -1.8941678613547872, -3.420798808626541, 3.2385910321015827, 3.0621948147263325, -2.7414576320923714, 1.0931345828715988, -1.4121928657421614, -2.927682152243278, -2.579240984661961, 1.2909042044871075, 1.4353978739599613, 3.0511991455876637, 0.06917531275636396, 0.9814861246041161, -3.5331668233262463, -3.2112090071930006, -2.060955705198364, -3.8535621851613926, -2.3846012504858973, -1.2095974862909566, -1.555052291452859, -1.1268348295412378, -2.6488288493115464, 0.3059661067843779, 7.894701948453901], 'output': 0.9759396149740832, 'delta': 1.969933174166795e-05}], 'output_layer': [{'weights': [-9.256404112168838, 4.039446288913233], 'output': 0.006731335634553569, 'delta': -4.500587668770417e-05}, {'weights': [9.241180381932805, -4.032339592120863], 'output': 0.993216642240501, 'delta': 4.570181345949797e-05}]}\n"
     ]
    }
   ],
   "source": [
    "from FCNN import initialize_network, predict, train_network\n",
    "\n",
    "train_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in train_df.itertuples(index=False, name=None)\n",
    "]\n",
    "test_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in test_df.itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "n_inputs = len(train_dataset[0]) - 1\n",
    "n_outputs = 2 if MODE == \"breast_cancer\" else 4\n",
    "network = initialize_network(n_inputs, 1, n_outputs)\n",
    "trained_network = train_network(network, train_dataset, 0.2, NUM_EPOCHS, n_outputs)\n",
    "\n",
    "print(f\"All of the hyperparameters of this NN are: {trained_network}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9632107023411371\n",
      "Accuracy on test data: 0.9626865671641791\n"
     ]
    }
   ],
   "source": [
    "# TESTING ON UNSEEN DATA\n",
    "\n",
    "test_predictions = list()\n",
    "train_predictions = list()\n",
    "\n",
    "for row in test_dataset:\n",
    "    prediction = predict(trained_network, row)\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "for row in train_dataset:\n",
    "    prediction = predict(trained_network, row)\n",
    "    train_predictions.append(prediction)\n",
    "\n",
    "accuracy_on_test_data = accuracy_score(\n",
    "    [row[-1] for row in test_dataset], test_predictions\n",
    ")\n",
    "accuracy_on_train_data = accuracy_score(\n",
    "    [row[-1] for row in train_dataset], train_predictions\n",
    ")\n",
    "\n",
    "print(f\"Accuracy on training data: {accuracy_on_train_data}\")\n",
    "\n",
    "print(f\"Accuracy on test data: {accuracy_on_test_data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
