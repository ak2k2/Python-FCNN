{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "\n",
    "\n",
    "def convert_if_possible(val):\n",
    "    try:\n",
    "        float_val = float(val)\n",
    "        if float_val.is_integer():\n",
    "            return int(float_val)\n",
    "        else:\n",
    "            return float_val\n",
    "    except ValueError:\n",
    "        return val\n",
    "\n",
    "\n",
    "MODE = \"breast_cancer\"\n",
    "\n",
    "test_file = \"bc_test.csv\"\n",
    "train_file = \"bc_train.csv\"\n",
    "\n",
    "# use a converter to make sure that all integers in the file (wihtout .) are stored as integers in to pandas dataframe\n",
    "test_df = pd.read_csv(\n",
    "    test_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")\n",
    "train_df = pd.read_csv(\n",
    "    train_file, converters={i: convert_if_possible for i in range(1, 10)}, sep=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/armaan/Desktop/Fall-2023 Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# Show the plot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m do_clustering(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     test_df, train_df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m )  \u001b[39m# preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m do_clustering(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     test_df, train_df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )  \u001b[39m# preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\u001b[39;00m\n",
      "\u001b[1;32m/Users/armaan/Desktop/Fall-2023 Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_clustering\u001b[39m(test_df, train_df):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df \u001b[39m=\u001b[39m test_df  \u001b[39m# set the dataframe to the test dataframe\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     column_names \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfeature_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     column_names[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# set the last column to be the Y col (target)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armaan/Desktop/Fall-2023%20Classes/Sable-Artificial-Intelligence/NN/open_data.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# add column names to dataframe\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "def do_clustering(test_df, train_df):\n",
    "    df = test_df  # set the dataframe to the test dataframe\n",
    "    column_names = [f\"feature_{i}\" for i in len(df.columns)]\n",
    "    column_names[-1] = \"Y\"  # set the last column to be the Y col (target)\n",
    "    # add column names to dataframe\n",
    "    test_df.columns = column_names\n",
    "    train_df.columns = column_names\n",
    "    pairs = 5\n",
    "    # clusters = KMeans(n_clusters=2, init=\"k-means++\", max_iter=1000, random_state=0).fit(X)\n",
    "    # clusters = DBSCAN(eps=0.5, min_samples=5).fit(X) # this does -1 or 0\n",
    "    X = df.drop(\"Y\", axis=1)\n",
    "    clusters = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "    Y = df[\"Y\"]\n",
    "    print(clusters.labels_)\n",
    "    accuracy = accuracy_score(Y, clusters.labels_)\n",
    "\n",
    "    # All unique pairs of the first #'pairs' columns\n",
    "    pairs_of_columns = list(itertools.combinations(column_names[:pairs], 2))\n",
    "\n",
    "    n_pairs = len(pairs_of_columns)\n",
    "    grid_size = int(n_pairs**0.5) + 1  # Square root of number of pairs, rounded up\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    # Plot each pair in its respective subplot\n",
    "    for ax, (a, b) in zip(axes.flatten(), pairs_of_columns):\n",
    "        ax.scatter(df[a], df[b], c=clusters.labels_, s=3)\n",
    "        ax.set_xlabel(a)\n",
    "        ax.set_ylabel(b)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for i in range(n_pairs, grid_size**2):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "\n",
    "    # make a header nice loooking box for the title and some text\n",
    "    title = f\"KMeans (n=2) Clustering of Breast Cancer Data Feature Combinations. \\n\\nBINARY CLASSIFICATION ACCURACY: {str(accuracy * 100)+ '%'}\"\n",
    "\n",
    "    # Add a title and a subtitle\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "do_clustering(\n",
    "    test_df, train_df\n",
    ")  # preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features\n",
    "\n",
    "do_clustering(\n",
    "    test_df, train_df\n",
    ")  # preform kmeans clustering on the training data and display a plot of all combinations of the first 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=186.491\n",
      ">epoch=1, lrate=0.100, error=181.753\n",
      ">epoch=2, lrate=0.100, error=163.499\n",
      ">epoch=3, lrate=0.100, error=150.306\n",
      ">epoch=4, lrate=0.100, error=137.730\n",
      ">epoch=5, lrate=0.100, error=126.185\n",
      ">epoch=6, lrate=0.100, error=116.140\n",
      ">epoch=7, lrate=0.100, error=107.650\n",
      ">epoch=8, lrate=0.100, error=100.545\n",
      ">epoch=9, lrate=0.100, error=94.594\n",
      ">epoch=10, lrate=0.100, error=89.571\n",
      ">epoch=11, lrate=0.100, error=85.289\n",
      ">epoch=12, lrate=0.100, error=81.598\n",
      ">epoch=13, lrate=0.100, error=78.379\n",
      ">epoch=14, lrate=0.100, error=75.543\n",
      ">epoch=15, lrate=0.100, error=73.021\n",
      ">epoch=16, lrate=0.100, error=70.760\n",
      ">epoch=17, lrate=0.100, error=68.720\n",
      ">epoch=18, lrate=0.100, error=66.868\n",
      ">epoch=19, lrate=0.100, error=65.180\n",
      ">epoch=20, lrate=0.100, error=63.635\n",
      ">epoch=21, lrate=0.100, error=62.214\n",
      ">epoch=22, lrate=0.100, error=60.903\n",
      ">epoch=23, lrate=0.100, error=59.689\n",
      ">epoch=24, lrate=0.100, error=58.559\n",
      ">epoch=25, lrate=0.100, error=57.504\n",
      ">epoch=26, lrate=0.100, error=56.516\n",
      ">epoch=27, lrate=0.100, error=55.586\n",
      ">epoch=28, lrate=0.100, error=54.710\n",
      ">epoch=29, lrate=0.100, error=53.880\n",
      ">epoch=30, lrate=0.100, error=53.093\n",
      ">epoch=31, lrate=0.100, error=52.344\n",
      ">epoch=32, lrate=0.100, error=51.630\n",
      ">epoch=33, lrate=0.100, error=50.946\n",
      ">epoch=34, lrate=0.100, error=50.291\n",
      ">epoch=35, lrate=0.100, error=49.662\n",
      ">epoch=36, lrate=0.100, error=49.056\n",
      ">epoch=37, lrate=0.100, error=48.472\n",
      ">epoch=38, lrate=0.100, error=47.908\n",
      ">epoch=39, lrate=0.100, error=47.362\n",
      ">epoch=40, lrate=0.100, error=46.833\n",
      ">epoch=41, lrate=0.100, error=46.321\n",
      ">epoch=42, lrate=0.100, error=45.823\n",
      ">epoch=43, lrate=0.100, error=45.339\n",
      ">epoch=44, lrate=0.100, error=44.868\n",
      ">epoch=45, lrate=0.100, error=44.410\n",
      ">epoch=46, lrate=0.100, error=43.963\n",
      ">epoch=47, lrate=0.100, error=43.528\n",
      ">epoch=48, lrate=0.100, error=43.104\n",
      ">epoch=49, lrate=0.100, error=42.690\n",
      ">epoch=50, lrate=0.100, error=42.286\n",
      ">epoch=51, lrate=0.100, error=41.892\n",
      ">epoch=52, lrate=0.100, error=41.508\n",
      ">epoch=53, lrate=0.100, error=41.132\n",
      ">epoch=54, lrate=0.100, error=40.765\n",
      ">epoch=55, lrate=0.100, error=40.406\n",
      ">epoch=56, lrate=0.100, error=40.056\n",
      ">epoch=57, lrate=0.100, error=39.714\n",
      ">epoch=58, lrate=0.100, error=39.379\n",
      ">epoch=59, lrate=0.100, error=39.051\n",
      ">epoch=60, lrate=0.100, error=38.731\n",
      ">epoch=61, lrate=0.100, error=38.417\n",
      ">epoch=62, lrate=0.100, error=38.110\n",
      ">epoch=63, lrate=0.100, error=37.809\n",
      ">epoch=64, lrate=0.100, error=37.514\n",
      ">epoch=65, lrate=0.100, error=37.224\n",
      ">epoch=66, lrate=0.100, error=36.941\n",
      ">epoch=67, lrate=0.100, error=36.662\n",
      ">epoch=68, lrate=0.100, error=36.388\n",
      ">epoch=69, lrate=0.100, error=36.120\n",
      ">epoch=70, lrate=0.100, error=35.856\n",
      ">epoch=71, lrate=0.100, error=35.596\n",
      ">epoch=72, lrate=0.100, error=35.341\n",
      ">epoch=73, lrate=0.100, error=35.091\n",
      ">epoch=74, lrate=0.100, error=34.845\n",
      ">epoch=75, lrate=0.100, error=34.602\n",
      ">epoch=76, lrate=0.100, error=34.365\n",
      ">epoch=77, lrate=0.100, error=34.131\n",
      ">epoch=78, lrate=0.100, error=33.901\n",
      ">epoch=79, lrate=0.100, error=33.675\n",
      ">epoch=80, lrate=0.100, error=33.454\n",
      ">epoch=81, lrate=0.100, error=33.236\n",
      ">epoch=82, lrate=0.100, error=33.022\n",
      ">epoch=83, lrate=0.100, error=32.812\n",
      ">epoch=84, lrate=0.100, error=32.606\n",
      ">epoch=85, lrate=0.100, error=32.404\n",
      ">epoch=86, lrate=0.100, error=32.206\n",
      ">epoch=87, lrate=0.100, error=32.012\n",
      ">epoch=88, lrate=0.100, error=31.821\n",
      ">epoch=89, lrate=0.100, error=31.634\n",
      ">epoch=90, lrate=0.100, error=31.451\n",
      ">epoch=91, lrate=0.100, error=31.272\n",
      ">epoch=92, lrate=0.100, error=31.096\n",
      ">epoch=93, lrate=0.100, error=30.924\n",
      ">epoch=94, lrate=0.100, error=30.755\n",
      ">epoch=95, lrate=0.100, error=30.590\n",
      ">epoch=96, lrate=0.100, error=30.428\n",
      ">epoch=97, lrate=0.100, error=30.269\n",
      ">epoch=98, lrate=0.100, error=30.113\n",
      ">epoch=99, lrate=0.100, error=29.960\n",
      "All of the hyperparameters of this NN are: {'hidden_layer': [{'weights': [-0.412822930323596, -1.7401579158947762, 0.7438681956484188, -1.3978069615463604, 0.8169175350242903, 0.5700458190249273, -1.393553872902511, -4.091789548568147, 2.4595925078696803, 3.5464243387354455, -1.7754730808718266, 0.9957229330265992, -2.040606269613771, -1.1672878271664977, -1.0680485116313556, 1.4273566933188149, 1.0595926222873169, 1.2051781088363844, -0.48861670357456305, 1.2387851958366611, -1.5905448608346977, -3.19221170616945, -1.574187725516257, -2.926875684651051, -1.3494934102849707, -0.8856222727438405, -1.5131159959894034, -2.0548060513988093, -1.302887698127689, 0.5286618012888582, 4.718818723221545], 'output': 0.9513026368543849, 'delta': 0.00017198642137885323}], 'output_layer': [{'weights': [-8.037638927056117, 3.4822344521850184], 'output': 0.015308069918446377, 'delta': -0.0002307497573767175}, {'weights': [8.035574375534692, -3.481276874630591], 'output': 0.9846767506292888, 'delta': 0.00023120404211838817}]}\n"
     ]
    }
   ],
   "source": [
    "from FCNN import (\n",
    "    initialize_network,\n",
    "    predict,\n",
    "    train_network,\n",
    "    read_configuration_file,\n",
    "    accuracy_score,\n",
    "    F1_score,\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in train_df.itertuples(index=False, name=None)\n",
    "]\n",
    "test_dataset = [\n",
    "    [*row[:-1], int(row[-1])] for row in test_df.itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "n_inputs = len(train_dataset[0]) - 1\n",
    "n_outputs = 2 if MODE == \"breast_cancer\" else 4\n",
    "network = initialize_network(n_inputs, 1, n_outputs)\n",
    "trained_network = train_network(network, train_dataset, 0.1, NUM_EPOCHS, n_outputs)\n",
    "\n",
    "print(f\"All of the hyperparameters of this NN are: {trained_network}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 96.98996655518395\n",
      "F1 score on training data: 0.9698996655518395\n",
      "\n",
      "Accuracy on test data: 97.01492537313433\n",
      "F1 score on test data: 0.9701492537313433\n"
     ]
    }
   ],
   "source": [
    "# TESTING ON UNSEEN DATA\n",
    "\n",
    "test_predictions = list()\n",
    "train_predictions = list()\n",
    "\n",
    "for row in test_dataset:\n",
    "    prediction = predict(trained_network, row)\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "for row in train_dataset:\n",
    "    prediction = predict(trained_network, row)\n",
    "    train_predictions.append(prediction)\n",
    "\n",
    "accuracy_on_test_data = accuracy_score(\n",
    "    [row[-1] for row in test_dataset], test_predictions\n",
    ")\n",
    "accuracy_on_train_data = accuracy_score(\n",
    "    [row[-1] for row in train_dataset], train_predictions\n",
    ")\n",
    "\n",
    "f1_test = F1_score([row[-1] for row in test_dataset], test_predictions)\n",
    "f1_train = F1_score([row[-1] for row in train_dataset], train_predictions)\n",
    "\n",
    "print(f\"Accuracy on training data: {accuracy_on_train_data}\")\n",
    "print(f\"F1 score on training data: {f1_train}\")\n",
    "print()\n",
    "print(f\"Accuracy on test data: {accuracy_on_test_data}\")\n",
    "print(f\"F1 score on test data: {f1_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
